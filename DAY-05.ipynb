{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37fa4f31-84e6-4ad9-b743-15edd259777d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "42448764"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Loading Data\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "delta_path = \"/Volumes/workspace/ecommerce/ecommerce_data/delta/events_oct\"\n",
    "\n",
    "deltaTable = DeltaTable.forPath(spark, delta_path)\n",
    "spark.read.format(\"delta\").load(delta_path).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a502202-f97e-49cc-926a-04692c9bf5c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " #Defining Schema\n",
    "from pyspark.sql.types import StructType, StructField, TimestampType, StringType, LongType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"event_time\", TimestampType(), True),\n",
    "    StructField(\"event_type\", StringType(), True),\n",
    "    StructField(\"product_id\", LongType(), True),\n",
    "    StructField(\"category_id\", LongType(), True),\n",
    "    StructField(\"category_code\", StringType(), True),\n",
    "    StructField(\"brand\", StringType(), True),\n",
    "    StructField(\"price\", DoubleType(), True),\n",
    "    StructField(\"user_id\", LongType(), True),\n",
    "    StructField(\"user_session\", StringType(), True)\n",
    "])\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3053c3b4-bf0d-4f99-a3fa-eb925d5439bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-----------+--------------------+----------+-----+-------+--------------+\n|         event_time|event_type|product_id|category_id|       category_code|     brand|price|user_id|  user_session|\n+-------------------+----------+----------+-----------+--------------------+----------+-----+-------+--------------+\n|2019-10-01 00:00:00|  purchase|    999999|      12345|electronics.smart...| TestBrand|499.0| 888888|session_test_1|\n|2019-10-01 00:01:00|      view|    999998|      12346|   electronics.audio|TestBrand2| 99.0| 777777|session_test_2|\n+-------------------+----------+----------+-----------+--------------------+----------+-----+-------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# creating sample dataframe\n",
    "from pyspark.sql.types import StructType, StructField, TimestampType, StringType, LongType, DoubleType\n",
    "from datetime import datetime\n",
    "\n",
    "updates = spark.createDataFrame(\n",
    "    [\n",
    "        (datetime(2019,10,1,0,0,0), \"purchase\", 999999, 12345, \"electronics.smartphone\", \"TestBrand\", 499.0, 888888, \"session_test_1\"),\n",
    "        (datetime(2019,10,1,0,1,0), \"view\",     999998, 12346, \"electronics.audio\",       \"TestBrand2\", 99.0,  777777, \"session_test_2\")\n",
    "    ],\n",
    "    schema=schema\n",
    ")\n",
    "updates.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0fb585f-3662-47cb-a3f5-631d630d0e9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[num_affected_rows: bigint, num_updated_rows: bigint, num_deleted_rows: bigint, num_inserted_rows: bigint]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Merging with the delta table\n",
    "deltaTable.alias(\"t\").merge(\n",
    "    updates.alias(\"s\"),\n",
    "    \"t.user_session = s.user_session AND t.event_time = s.event_time\"\n",
    ").whenMatchedUpdateAll() \\\n",
    " .whenNotMatchedInsertAll() \\\n",
    " .execute()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8460551f-9fa5-46ab-8c57-b8815905e671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+----------+-----------+--------------------+----------+-----+-------+--------------+\n|         event_time|event_type|product_id|category_id|       category_code|     brand|price|user_id|  user_session|\n+-------------------+----------+----------+-----------+--------------------+----------+-----+-------+--------------+\n|2019-10-01 00:00:00|  purchase|    999999|      12345|electronics.smart...| TestBrand|499.0| 888888|session_test_1|\n|2019-10-01 00:01:00|      view|    999998|      12346|   electronics.audio|TestBrand2| 99.0| 777777|session_test_2|\n+-------------------+----------+----------+-----------+--------------------+----------+-----+-------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    " #verfying the merge\n",
    "spark.read.format(\"delta\").load(delta_path) \\\n",
    "     .filter(\"user_session LIKE 'session_test_%'\") \\\n",
    "     .show()\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "def72b45-bead-43ae-8d07-f6b01b0ac801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: 42448766\nVersion 0: 42448764\n"
     ]
    }
   ],
   "source": [
    "# checking version history\n",
    "# Current count\n",
    "current = spark.read.format(\"delta\").load(delta_path).count()\n",
    "\n",
    "# Version 0\n",
    "v0 = spark.read.format(\"delta\") \\\n",
    "    .option(\"versionAsOf\", 0) \\\n",
    "    .load(delta_path)\n",
    "\n",
    "print(\"Current:\", current)\n",
    "print(\"Version 0:\", v0.count())\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b1d8573-bd0b-487d-883d-ac522ae79ee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[path: string, metrics: struct<numFilesAdded:bigint,numFilesRemoved:bigint,filesAdded:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,filesRemoved:struct<min:bigint,max:bigint,avg:double,totalFiles:bigint,totalSize:bigint>,partitionsOptimized:bigint,zOrderStats:struct<strategyName:string,inputCubeFiles:struct<num:bigint,size:bigint>,inputOtherFiles:struct<num:bigint,size:bigint>,inputNumCubes:bigint,mergedFiles:struct<num:bigint,size:bigint>,numOutputCubes:bigint,mergedNumCubes:bigint>,clusteringStats:struct<inputZCubeFiles:struct<numFiles:bigint,size:bigint>,inputOtherFiles:struct<numFiles:bigint,size:bigint>,inputNumZCubes:bigint,mergedFiles:struct<numFiles:bigint,size:bigint>,numOutputZCubes:bigint>,numBins:bigint,numBatches:bigint,totalConsideredFiles:bigint,totalFilesSkipped:bigint,preserveInsertionOrder:boolean,numFilesSkippedToReduceWriteAmplification:bigint,numBytesSkippedToReduceWriteAmplification:bigint,startTimeMs:bigint,endTimeMs:bigint,totalClusterParallelism:bigint,totalScheduledTasks:bigint,autoCompactParallelismStats:struct<maxClusterActiveParallelism:bigint,minClusterActiveParallelism:bigint,maxSessionActiveParallelism:bigint,minSessionActiveParallelism:bigint>,deletionVectorStats:struct<numDeletionVectorsRemoved:bigint,numDeletionVectorRowsRemoved:bigint>,recompressionCodec:string,numTableColumns:bigint,numTableColumnsWithStats:bigint,totalTaskExecutionTimeMs:bigint,skippedArchivedFiles:bigint,clusteringMetrics:struct<sizeOfTableInBytesBeforeLazyClustering:bigint,isNewMetadataCreated:boolean,isPOTriggered:boolean,isFull:boolean,approxClusteringQuality:double,approxClusteringQualityPerColumn:array<double>,approxClusteringCoverage:double,compactionType:string,numFilesSkippedWithoutStats:bigint,numFilesClassifiedToIntermediateNodes:bigint,sizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,logicalSizeOfFilesClassifiedToIntermediateNodesInBytes:bigint,numFilesClassifiedToLeafNodes:bigint,sizeOfFilesClassifiedToLeafNodesInBytes:bigint,logicalSizeOfFilesClassifiedToLeafNodesInBytes:bigint,numThreadsForClassifier:int,clusterThresholdStrategy:string,minFileSize:bigint,maxFileSize:bigint,nodeMinNumFilesToCompact:bigint,numIdealFiles:bigint,numIdealFilesWithTrimmedStringMaxValue:bigint,numAddedFilesWithSameMinMaxOnClusteringColumns:array<bigint>,numClusteringTasksPlanned:int,numClusteringTasksNotPlannedDueToPO:int,numCompactionTasksPlanned:int,numCompactionTasksPlannedUndoneDueToPO:int,numOptimizeBatchesPlanned:int,numLeafNodesExpanded:bigint,numLeafNodesClustered:bigint,numGetFilesForNodeCalls:bigint,numSamplingJobs:bigint,numLeafNodesCompacted:bigint,numLeafNodesCompactedUndoneDueToPO:bigint,numIntermediateNodesCompacted:bigint,numIntermediateNodesCompactedUndoneDueToPO:bigint,totalSizeOfDataToCompactInBytes:bigint,totalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,totalLogicalSizeOfDataToCompactInBytes:bigint,totalLogicalSizeOfDataToCompactInBytesUndoneDueToPO:bigint,numIntermediateNodesClustered:bigint,numFilesSkippedAfterExpansion:bigint,totalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalLogicalSizeOfFilesSkippedAfterExpansionInBytes:bigint,totalSizeOfDataToRewriteInBytes:bigint,totalLogicalSizeOfDataToRewriteInBytes:bigint,timeMetrics:struct<classifierTimeMs:bigint,optimizerTimeMs:bigint,metadataLoadTimeMs:bigint,totalGetFilesForNodeCallsTimeMs:bigint,totalSamplingTimeMs:bigint,metadataCreationTimeMs:bigint>,maxOptimizeBatchesInParallel:bigint,currentIteration:int,maxIterations:int,clusteringStrategy:string>>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# running optimization on table\n",
    "spark.sql(\"OPTIMIZE events_table ZORDER BY (event_type, user_id)\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e7d1b98-ae32-4aa7-94bf-51a0ae494436",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[path: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Performing cleanup\n",
    "spark.sql(\"VACUUM events_table RETAIN 168 HOURS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5dff776b-8ac7-4b14-b404-44443a441266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DAY-05",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}